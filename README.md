# Shadow Knowledge Distillation

This project provides Pytorch implementation for Shadow Knowledge Distillation: Bridging Offline and Online Knowledge Transfer.

**Open source code and training logs are under preparation, please keep patience, thanks!**



## Acknowledgements
This repo is partly based on the following repos, thank the authors a lot.
- [HobbitLong/RepDistiller](https://github.com/HobbitLong/RepDistiller)
- [Knowledge-Distillation-Zoo](https://github.com/AberHu/Knowledge-Distillation-Zoo)

## Citation
If you find that this project helps your research, please consider citing some of the following papers:

```

```

